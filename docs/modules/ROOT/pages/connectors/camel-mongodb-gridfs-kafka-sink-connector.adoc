// kafka-connector options: START
[[camel-mongodb-gridfs-kafka-connector-sink]]
= camel-mongodb-gridfs-kafka-connector sink configuration

When using camel-mongodb-gridfs-kafka-connector as sink make sure to use the following Maven dependency to have support for the connector:

[source,xml]
----
<dependency>
  <groupId>org.apache.camel.kafkaconnector</groupId>
  <artifactId>camel-mongodb-gridfs-kafka-connector</artifactId>
  <version>x.x.x</version>
  <!-- use the same version as your Camel Kafka connector version -->
</dependency>
----

To use this Sink connector in Kafka connect you'll need to set the following connector.class

[source,java]
----
connector.class=org.apache.camel.kafkaconnector.mongodbgridfs.CamelMongodbgridfsSinkConnector
----


The camel-mongodb-gridfs sink connector supports 11 options, which are listed below.



[width="100%",cols="2,5,^1,2",options="header"]
|===
| Name | Description | Default | Priority
| *camel.sink.path.connectionBean* | Name of com.mongodb.client.MongoClient to use. | null | HIGH
| *camel.sink.endpoint.bucket* | Sets the name of the GridFS bucket within the database. Default is fs. | "fs" | MEDIUM
| *camel.sink.endpoint.database* | Sets the name of the MongoDB database to target | null | HIGH
| *camel.sink.endpoint.readPreference* | Sets a MongoDB ReadPreference on the Mongo connection. Read preferences set directly on the connection will be overridden by this setting. The com.mongodb.ReadPreference#valueOf(String) utility method is used to resolve the passed readPreference value. Some examples for the possible values are nearest, primary or secondary etc. | null | MEDIUM
| *camel.sink.endpoint.writeConcern* | Set the WriteConcern for write operations on MongoDB using the standard ones. Resolved from the fields of the WriteConcern class by calling the WriteConcern#valueOf(String) method. One of: [ACKNOWLEDGED] [W1] [W2] [W3] [UNACKNOWLEDGED] [JOURNALED] [MAJORITY] | null | MEDIUM
| *camel.sink.endpoint.lazyStartProducer* | Whether the producer should be started lazy (on the first message). By starting lazy you can use this to allow CamelContext and routes to startup in situations where a producer may otherwise fail during starting and cause the route to fail being started. By deferring this startup to be lazy then the startup failure can be handled during routing messages via Camel's routing error handlers. Beware that when the first message is processed then creating and starting the producer may take a little time and prolong the total processing time of the processing. | false | MEDIUM
| *camel.sink.endpoint.operation* | Sets the operation this endpoint will execute against GridFs. | null | MEDIUM
| *camel.sink.endpoint.basicPropertyBinding* | Whether the endpoint should use basic property binding (Camel 2.x) or the newer property binding with additional capabilities | false | MEDIUM
| *camel.sink.endpoint.synchronous* | Sets whether synchronous processing should be strictly used, or Camel is allowed to use asynchronous processing (if supported). | false | MEDIUM
| *camel.component.mongodb-gridfs.lazyStartProducer* | Whether the producer should be started lazy (on the first message). By starting lazy you can use this to allow CamelContext and routes to startup in situations where a producer may otherwise fail during starting and cause the route to fail being started. By deferring this startup to be lazy then the startup failure can be handled during routing messages via Camel's routing error handlers. Beware that when the first message is processed then creating and starting the producer may take a little time and prolong the total processing time of the processing. | false | MEDIUM
| *camel.component.mongodb-gridfs.basicProperty Binding* | Whether the component should use basic property binding (Camel 2.x) or the newer property binding with additional capabilities | false | LOW
|===



The camel-mongodb-gridfs sink connector has no converters out of the box.





The camel-mongodb-gridfs sink connector has no transforms out of the box.





The camel-mongodb-gridfs sink connector has no aggregation strategies out of the box.
// kafka-connector options: END
