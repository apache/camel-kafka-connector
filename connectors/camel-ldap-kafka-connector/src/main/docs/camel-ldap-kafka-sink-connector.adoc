// kafka-connector options: START
[[camel-ldap-kafka-connector-sink]]
= camel-ldap-kafka-connector sink configuration

When using camel-ldap-kafka-connector as sink make sure to use the following Maven dependency to have support for the connector:

[source,xml]
----
<dependency>
  <groupId>org.apache.camel.kafkaconnector</groupId>
  <artifactId>camel-ldap-kafka-connector</artifactId>
  <version>x.x.x</version>
  <!-- use the same version as your Camel Kafka connector version -->
</dependency>
----

To use this Sink connector in Kafka connect you'll need to set the following connector.class

[source,java]
----
connector.class=org.apache.camel.kafkaconnector.ldap.CamelLdapSinkConnector
----


The camel-ldap sink connector supports 8 options, which are listed below.



[width="100%",cols="2,5,^1,1,1",options="header"]
|===
| Name | Description | Default | Required | Priority
| *camel.sink.path.dirContextName* | Name of either a javax.naming.directory.DirContext, or java.util.Hashtable, or Map bean to lookup in the registry. If the bean is either a Hashtable or Map then a new javax.naming.directory.DirContext instance is created for each use. If the bean is a javax.naming.directory.DirContext then the bean is used as given. The latter may not be possible in all situations where the javax.naming.directory.DirContext must not be shared, and in those situations it can be better to use java.util.Hashtable or Map instead. | null | true | HIGH
| *camel.sink.endpoint.base* | The base DN for searches. | "ou=system" | false | MEDIUM
| *camel.sink.endpoint.lazyStartProducer* | Whether the producer should be started lazy (on the first message). By starting lazy you can use this to allow CamelContext and routes to startup in situations where a producer may otherwise fail during starting and cause the route to fail being started. By deferring this startup to be lazy then the startup failure can be handled during routing messages via Camel's routing error handlers. Beware that when the first message is processed then creating and starting the producer may take a little time and prolong the total processing time of the processing. | false | false | MEDIUM
| *camel.sink.endpoint.pageSize* | When specified the ldap module uses paging to retrieve all results (most LDAP Servers throw an exception when trying to retrieve more than 1000 entries in one query). To be able to use this a LdapContext (subclass of DirContext) has to be passed in as ldapServerBean (otherwise an exception is thrown) | null | false | MEDIUM
| *camel.sink.endpoint.returnedAttributes* | Comma-separated list of attributes that should be set in each entry of the result | null | false | MEDIUM
| *camel.sink.endpoint.scope* | Specifies how deeply to search the tree of entries, starting at the base DN. One of: [object] [onelevel] [subtree] | "subtree" | false | MEDIUM
| *camel.component.ldap.lazyStartProducer* | Whether the producer should be started lazy (on the first message). By starting lazy you can use this to allow CamelContext and routes to startup in situations where a producer may otherwise fail during starting and cause the route to fail being started. By deferring this startup to be lazy then the startup failure can be handled during routing messages via Camel's routing error handlers. Beware that when the first message is processed then creating and starting the producer may take a little time and prolong the total processing time of the processing. | false | false | MEDIUM
| *camel.component.ldap.autowiredEnabled* | Whether autowiring is enabled. This is used for automatic autowiring options (the option must be marked as autowired) by looking up in the registry to find if there is a single instance of matching type, which then gets configured on the component. This can be used for automatic configuring JDBC data sources, JMS connection factories, AWS Clients, etc. | true | false | MEDIUM
|===



The camel-ldap sink connector has no converters out of the box.





The camel-ldap sink connector has no transforms out of the box.





The camel-ldap sink connector has no aggregation strategies out of the box.
// kafka-connector options: END
