{
	"connector": {
		"class": "org.apache.camel.kafkaconnector.kafkabatchsource.CamelKafkabatchsourceSourceConnector",
		"artifactId": "camel-kafka-batch-source-kafka-connector",
		"groupId": "org.apache.camel.kafkaconnector",
		"id": "camel-kafka-batch-source-source",
		"type": "source",
		"version": "4.10.3",
		"description": "Receive data from Kafka topics in batch through Plain Login Module and commit them manually through KafkaManualCommit.."
	},
	"properties": {
		"camel.kamelet.kafka-batch-source.topic": {
			"name": "camel.kamelet.kafka-batch-source.topic",
			"description": "Comma separated list of Kafka topic names",
			"priority": "HIGH",
			"required": "true"
		},
		"camel.kamelet.kafka-batch-source.bootstrapServers": {
			"name": "camel.kamelet.kafka-batch-source.bootstrapServers",
			"description": "Comma separated list of Kafka Broker URLs",
			"priority": "HIGH",
			"required": "true"
		},
		"camel.kamelet.kafka-batch-source.securityProtocol": {
			"name": "camel.kamelet.kafka-batch-source.securityProtocol",
			"description": "Protocol used to communicate with brokers. SASL_PLAINTEXT, PLAINTEXT, SASL_SSL and SSL are supported",
			"defaultValue": "\"SASL_SSL\"",
			"priority": "MEDIUM",
			"required": "false"
		},
		"camel.kamelet.kafka-batch-source.saslMechanism": {
			"name": "camel.kamelet.kafka-batch-source.saslMechanism",
			"description": "The Simple Authentication and Security Layer (SASL) Mechanism used.",
			"defaultValue": "\"PLAIN\"",
			"priority": "MEDIUM",
			"required": "false"
		},
		"camel.kamelet.kafka-batch-source.user": {
			"name": "camel.kamelet.kafka-batch-source.user",
			"description": "Username to authenticate to Kafka",
			"priority": "HIGH",
			"required": "true"
		},
		"camel.kamelet.kafka-batch-source.password": {
			"name": "camel.kamelet.kafka-batch-source.password",
			"description": "Password to authenticate to kafka",
			"priority": "HIGH",
			"required": "true"
		},
		"camel.kamelet.kafka-batch-source.autoCommitEnable": {
			"name": "camel.kamelet.kafka-batch-source.autoCommitEnable",
			"description": "If true, periodically commit to ZooKeeper the offset of messages already fetched by the consumer",
			"defaultValue": "true",
			"priority": "MEDIUM",
			"required": "false"
		},
		"camel.kamelet.kafka-batch-source.allowManualCommit": {
			"name": "camel.kamelet.kafka-batch-source.allowManualCommit",
			"description": "Whether to allow doing manual commits",
			"defaultValue": "false",
			"priority": "MEDIUM",
			"required": "false"
		},
		"camel.kamelet.kafka-batch-source.pollOnError": {
			"name": "camel.kamelet.kafka-batch-source.pollOnError",
			"description": "What to do if kafka threw an exception while polling for new messages. There are 5 enums and the value can be one of DISCARD, ERROR_HANDLER, RECONNECT, RETRY, STOP",
			"defaultValue": "\"ERROR_HANDLER\"",
			"priority": "MEDIUM",
			"required": "false"
		},
		"camel.kamelet.kafka-batch-source.autoOffsetReset": {
			"name": "camel.kamelet.kafka-batch-source.autoOffsetReset",
			"description": "What to do when there is no initial offset. There are 3 enums and the value can be one of latest, earliest, none",
			"defaultValue": "\"latest\"",
			"priority": "MEDIUM",
			"required": "false"
		},
		"camel.kamelet.kafka-batch-source.consumerGroup": {
			"name": "camel.kamelet.kafka-batch-source.consumerGroup",
			"description": "A string that uniquely identifies the group of consumers to which this source belongs Example: my-group-id",
			"priority": "MEDIUM",
			"required": "false"
		},
		"camel.kamelet.kafka-batch-source.deserializeHeaders": {
			"name": "camel.kamelet.kafka-batch-source.deserializeHeaders",
			"description": "When enabled the Kamelet source will deserialize all message headers to String representation.",
			"defaultValue": "true",
			"priority": "MEDIUM",
			"required": "false"
		},
		"camel.kamelet.kafka-batch-source.batchSize": {
			"name": "camel.kamelet.kafka-batch-source.batchSize",
			"description": "The maximum number of records returned in a single call to poll()",
			"defaultValue": "500",
			"priority": "MEDIUM",
			"required": "false"
		},
		"camel.kamelet.kafka-batch-source.pollTimeout": {
			"name": "camel.kamelet.kafka-batch-source.pollTimeout",
			"description": "The timeout used when polling the KafkaConsumer",
			"defaultValue": "5000",
			"priority": "MEDIUM",
			"required": "false"
		},
		"camel.kamelet.kafka-batch-source.maxPollIntervalMs": {
			"name": "camel.kamelet.kafka-batch-source.maxPollIntervalMs",
			"description": "The maximum delay between invocations of poll() when using consumer group management",
			"priority": "MEDIUM",
			"required": "false"
		},
		"camel.kamelet.kafka-batch-source.batchingIntervalMs": {
			"name": "camel.kamelet.kafka-batch-source.batchingIntervalMs",
			"description": "In consumer batching mode, then this option is specifying a time in millis, to trigger batch completion eager when the current batch size has not reached the maximum size defined by maxPollRecords. Notice the trigger is not exact at the given interval, as this can only happen between kafka polls (see pollTimeoutMs option).",
			"priority": "MEDIUM",
			"required": "false"
		},
		"camel.kamelet.kafka-batch-source.topicIsPattern": {
			"name": "camel.kamelet.kafka-batch-source.topicIsPattern",
			"description": "Whether the topic is a pattern (regular expression). This can be used to subscribe to dynamic number of topics matching the pattern.",
			"defaultValue": "false",
			"priority": "MEDIUM",
			"required": "false"
		}
	}
}