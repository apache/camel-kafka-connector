# ---------------------------------------------------------------------------
# Licensed to the Apache Software Foundation (ASF) under one or more
# contributor license agreements.  See the NOTICE file distributed with
# this work for additional information regarding copyright ownership.
# The ASF licenses this file to You under the Apache License, Version 2.0
# (the "License"); you may not use this file except in compliance with
# the License.  You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# ---------------------------------------------------------------------------
apiVersion: camel.apache.org/v1
kind: Kamelet
metadata:
  name: kafka-batch-scram-source
  annotations:
    camel.apache.org/kamelet.support.level: "Preview"
    camel.apache.org/catalog.version: "4.11.0-SNAPSHOT"
    camel.apache.org/kamelet.icon: "data:image/svg+xml;base64,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"
    camel.apache.org/provider: "Apache Software Foundation"
    camel.apache.org/kamelet.group: "Kafka"
    camel.apache.org/kamelet.namespace: "Kafka"
    camel.apache.org/keda.type: "kafka"
    camel.apache.org/keda.authentication.sasl: "scram-sha-512"
    camel.apache.org/keda.authentication.tls: "enable"
  labels:
    camel.apache.org/kamelet.type: "source"
spec:
  definition:
    title: "Kafka Batch Scram Source"
    description: |-
      Receive data from Kafka topics in batch through SCRAM login module and commit them manually through KafkaManualCommit..
    required:
      - topic
      - bootstrapServers
      - user
      - password
    type: object
    properties:
      topic:
        title: Topic Names
        description: Comma separated list of Kafka topic names
        type: string
        x-descriptors:
        - urn:keda:metadata:topic
        - urn:keda:required
      bootstrapServers:
        title: Bootstrap Servers
        description: Comma separated list of Kafka Broker URLs
        type: string
        x-descriptors:
        - urn:keda:metadata:bootstrapServers
        - urn:keda:required
      securityProtocol:
        title: Security Protocol
        description: Protocol used to communicate with brokers. SASL_PLAINTEXT, PLAINTEXT, SASL_SSL and SSL are supported
        type: string
        default: SASL_SSL
      saslMechanism:
        title: SASL Mechanism
        description: The Simple Authentication and Security Layer (SASL) Mechanism used.
        type: string
        default: SCRAM-SHA-512
      user:
        title: Username
        description: Username to authenticate to Kafka
        type: string
        x-descriptors:
        - urn:camel:group:credentials
        - urn:keda:authentication:username
        - urn:keda:required
      password:
        title: Password
        description: Password to authenticate to kafka
        type: string
        format: password
        x-descriptors:
        - urn:camel:group:credentials
        - urn:keda:authentication:password
        - urn:keda:required
      autoCommitEnable:
        title: Auto Commit Enable
        description: If true, periodically commit to ZooKeeper the offset of messages already fetched by the consumer
        type: boolean
        default: true
      allowManualCommit:
        title: Allow Manual Commit
        description: Whether to allow doing manual commits
        type: boolean
        default: false
      pollOnError:
        title: Poll On Error Behavior
        description: What to do if kafka threw an exception while polling for new messages. There are 5 enums and the value can be one of DISCARD, ERROR_HANDLER, RECONNECT, RETRY, STOP
        type: string
        default: "ERROR_HANDLER"
      autoOffsetReset:
        title: Auto Offset Reset
        description: What to do when there is no initial offset. There are 3 enums and the value can be one of latest, earliest, none
        type: string
        default: "latest"
        x-descriptors:
        - urn:keda:metadata:offsetResetPolicy
      consumerGroup:
        title: Consumer Group
        description: A string that uniquely identifies the group of consumers to which this source belongs
        type: string
        example: "my-group-id"
        x-descriptors:
        - urn:keda:metadata:consumerGroup
        - urn:keda:required
      deserializeHeaders:
        title: Automatically Deserialize Headers
        description: When enabled the Kamelet source will deserialize all message headers to String representation.
        type: boolean
        default: true
      batchSize:
        title: Batch Dimension
        description: The maximum number of records returned in a single call to poll()
        type: int
        default: 500
      pollTimeout:
        title: Poll Timeout Interval
        description: The timeout used when polling the KafkaConsumer
        type: int
        default: 5000
      maxPollIntervalMs:
        title: Max Poll Interval
        description: The maximum delay between invocations of poll() when using consumer group management
        type: int
      batchingIntervalMs:
        title: Batching Interval
        description: In consumer batching mode, then this option is specifying a time in millis, to trigger batch completion eager when the current batch size has not reached the maximum size defined by maxPollRecords. Notice the trigger is not exact at the given interval, as this can only happen between kafka polls (see pollTimeoutMs option).
        type: int
      topicIsPattern:
        title: Topic Is Pattern
        description: Whether the topic is a pattern (regular expression). This can be used to subscribe to dynamic number of topics matching the pattern.
        type: boolean
        default: false
  dependencies:
    - "camel:core"
    - "camel:kafka"
    - "camel:kamelet"
  template:
    beans:
      - name: kafkaHeaderDeserializer
        type: "#class:org.apache.camel.component.kafka.KafkaHeaderDeserializer"
        properties:
          enabled: '{{deserializeHeaders}}'
      - name: manualCommitFactory
        type: "#class:org.apache.camel.component.kafka.consumer.DefaultKafkaManualCommitFactory"
    from:
      uri: "kafka:{{topic}}"
      parameters:
        brokers: "{{?bootstrapServers}}"
        securityProtocol: "{{securityProtocol}}"
        saslMechanism: "{{saslMechanism}}"
        saslJaasConfig: 'org.apache.kafka.common.security.scram.ScramLoginModule required username="{{user}}" password="{{password}}";'
        autoCommitEnable: "{{autoCommitEnable}}"
        allowManualCommit: "{{allowManualCommit}}"
        pollOnError: "{{pollOnError}}"
        autoOffsetReset: "{{autoOffsetReset}}"
        groupId: "{{?consumerGroup}}"
        maxPollRecords: "{{batchSize}}"
        pollTimeoutMs: "{{pollTimeout}}"
        maxPollIntervalMs: "{{?maxPollIntervalMs}}"
        batchingIntervalMs: "{{?batchingIntervalMs}}"
        batching: true
        kafkaManualCommitFactory: "#bean:{{manualCommitFactory}}"
        topicIsPattern: "{{topicIsPattern}}"
      steps:
        - process:
            ref: "{{kafkaHeaderDeserializer}}"
        - to: "kamelet:sink"